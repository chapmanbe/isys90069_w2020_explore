{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging NLP and Standards-based Documentation\n",
    "\n",
    "In this notebook, we present the very basic ideas that might go into creating a _post hoc_ system that would allow clinicians to generate text reports in a normal fashion and then generate standards-based documentation by identifying key concepts in the text using natural language processing and then linking these concepts to ontologies.\n",
    "\n",
    "## [Spacy](https://spacy.io/)\n",
    "\n",
    "In this notebook we will be using Spacy, an NLP library written in Python that has achieved great popularity. We will be using a statistical language model that has been trained on English clinical texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import medspacy\n",
    "from medspacy.visualization import visualize_ent\n",
    "\n",
    "from IPython.display import YouTubeVideo\n",
    "import os\n",
    "from cdsutils.bioportal.metadataCollector import *\n",
    "from ipywidgets import *\n",
    "import json\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REPORT_DIR = \"/home/shared/gen_reports\"\n",
    "\n",
    "with open(\".apikey\") as f0:\n",
    "    apiKey = f0.read().strip()\n",
    "username=\"bcchap\"\n",
    "OUTDIR = os.path.join(REPORT_DIR, username)\n",
    "if not os.path.exists(OUTDIR):\n",
    "    os.makedirs(OUTDIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = medspacy.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# We can use a machine learning system trained on some real medical reports marked up by humans to mark up problems, tests, and treatments in a clinical note\n",
    "\n",
    "## Here's a really quick description of how a machine learning algorithm works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YouTubeVideo(\"UEm7H8cfz80\", start=2600, end=2708, rel=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# V. Using a Pre-Trained Machine Learning Model\n",
    "With **statistical NLP**, you train a machine learning classifier to extract concepts based on annotated datasets.\n",
    "\n",
    "We'll use a model trained on the i2b2 2012 shared task: [**\"Evaluating temporal relations in clinical text\"**](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3756273/). This model was trained on data for the first subtask in the shared task, referred to in the challenge as **\"Clinically relevant events\"**. For the purpose of this module, I specifically restricted it to the following labels of **clinical concepts**:\n",
    "- **Problems:** Diagnoses, signs, and symptoms\n",
    "- **Tests:** Lab and vital measurements\n",
    "- **Treatments:** Medications, procedures, and therapies\n",
    "\n",
    "\n",
    "The model has been pre-installed and is available with the name **\"en_info_3700_i2b2_2012\"**. To install on your own machine, run this command to download and install the model:\n",
    "```pip\n",
    "pip install https://github.com/abchapman93/spacy_models/raw/master/releases/en_info_3700_i2b2_2012-0.1.0/dist/en_info_3700_i2b2_2012-0.1.0.tar.gz\n",
    "```\n",
    "\n",
    "We can load this using both spacy or medSpaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using spaCy\n",
    "# nlp = spacy.load(\"en_info_3700_i2b2_2012\")\n",
    "# Using medSpaCy\n",
    "nlp = medspacy.load(\"en_info_3700_i2b2_2012\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy Pipelines\n",
    "\n",
    "Spacy makes use of pipelines that can be refined by inserting, deleting, or overwriting steps. The current pipeline consists of the following steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what labels will be predicted by the NER component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner = nlp.get_pipe(\"ner\")\n",
    "ner.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what concepts are extracted by our model. Any of the target concepts in `doc.ents` will have been extracted by the statistical NER model. MedSpaCy will keep extracting the modifiers and section titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Past Medical History:\n",
    "1. Type II DM\n",
    "2. Afib\n",
    "3. CKD Stage 3\n",
    "\n",
    "Family History:\n",
    "1. Breast Cancer\n",
    "\n",
    "\n",
    "Reason for this examination: Possible pneumonia.\n",
    "\n",
    "IMPRESSION:\n",
    "No evidence of pneumonia.\n",
    "\n",
    "Assessment/Plan:\n",
    "Continue metformin for type 2 dm.\"\"\"\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(doc.ents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_ent(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How well does this NLP model work on radiology texts?\n",
    "### Here is a transcript of the report of my bone scan from 6 April 1976"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"SCAN IMPRESSION: Negative, essentially normal bone scan, with nonspecific increased\n",
    "activity in right ankle and foot markedly enlarged right kidney.\n",
    "\n",
    "\n",
    "BONE SCAN\n",
    "\n",
    "DOSE:     8.0 Millicuries diphosphonate.\n",
    "\n",
    "ADMISSION DIAGNOSIS:    Right kidney mass.\n",
    "\n",
    "BRIEF CLINICAL HISTORY:\n",
    "\n",
    "Patient had selective renal arteriogram, 4/5/76, which demonstrated a large vascular tumor \n",
    "of the right kidney suggestive of a Wilm's tumor.\n",
    "\n",
    "SCAN DESCRIPTION:\n",
    "\n",
    "This is a technetium polyphosphate bone scan. The study includes standard anterior\n",
    "and posterior views of major skeletal structures with lateral views of the skull and\n",
    "cervical spine. The scan appears entirely normal except that the right kidney is greatly\n",
    "enlarged, perhaps, 2.5 to 3 times the size of the left kidney. Also, in the region\n",
    "of the right ankle and foot there is increased diffuse activity, perhaps in soft tissue.\n",
    "The epiphyses are prominent in both ankles as in other long bones. The activity in the right \n",
    "foot and ankle does not appear to represent metastatic disease. The etiology of this is uncertain.\"\"\"\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's iterate through each item in doc (i.e., all of the problems, tests, and treatments identified by the machine learning system) and see if they are in Bioportal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_ent(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying Ontologies\n",
    "\n",
    "No single ontology is probably sufficient for medical documentation. The RSNA bone scan template explored in [Templated Documentation](templated_documentation.ipynb) used RadLex, LOINC, and SNOMEDCT. It may be desirable to have a different ontology for each of the three types of named entities that the NLP system recognizes: 'PROBLEM', 'TEST', and 'TREATMENT'. You can use the `ConceptSelector` instance below to see if you can find matches to the identified term in various ontologies. The second argument is a list of ontologies to search (e.g. `[\"LOINC\"]` or `[\"RADLEX\", \"DOID\"]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "termFinder = ConceptSelector(\"concept\", [\"LOINC\"], bioportal_api_key=apiKey)\n",
    "termFinder.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can also explore using some additional bone scan reports extracted from MIMIC II demo data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/shared/bone_scans.json\",\"r\") as f:\n",
    "    reports = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@interact(i=IntSlider(min=0,max=len(reports), value=0))\n",
    "def view_bone_scan_reports(i):\n",
    "    clear_output()\n",
    "    visualize_ent(nlp(reports[i]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions and Ideas\n",
    "\n",
    "1. the named entity recognition is only identifying three types. What additional categories would we need to recognize to make this useful?\n",
    "1. How much of an issue do you think it is that the language model was trained without reference to any of these ontologies?\n",
    "1. We are searching the entire ontology. However, you can change the Bioportal search to explore subsets of the ontology? How might this be useful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
