{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Who Are Our Rebels\n",
    "\n",
    "In this notebook I'm going to use some simple NLP to try to explore who were our favorite rebels. In the process I hope to demonstrate some of the data-wrangling challenges that go along with NLP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data from Canvas\n",
    "\n",
    "Canvas has a RESTful API. I'm going to use it to pull down the responses to the homework assignments.\n",
    "\n",
    "By the way, you can also use the Canvas API to access your data.\n",
    "\n",
    "The cell below contains the code I used to get the data from Canvas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```Python\n",
    "with open(os.path.join(os.path.expanduser(\"~\"), \".canvaslms\", \"quiz_token\")) as f:\n",
    "    token = f.read()\n",
    "    \n",
    "from canvasapi import Canvas\n",
    "from bs4 import BeautifulSoup\n",
    "import unicodedata\n",
    "\n",
    "API_URL = \"https://canvas.lms.unimelb.edu.au/\"\n",
    "canvas = Canvas(API_URL, token)\n",
    "bec = canvas.get_user(canvas.get_current_user().id)\n",
    "ehealth = canvas.get_course(110024)\n",
    "\n",
    "# This is the id number for the assignment\n",
    "rebel_id = 139157\n",
    "\n",
    "rebels = ehealth.get_assignment(rebel_id)\n",
    "\n",
    "rebel_submissions = rebels.get_submissions()\n",
    "\n",
    "responses = [(b.user_id, b.body) for b in rebel_submissions]\n",
    "\n",
    "\n",
    "len(responses)\n",
    "\n",
    "len(set([r[0] for r in responses]))\n",
    "\n",
    "rebel_text = [unicodedata.normalize(\"NFKC\", BeautifulSoup(r[1]).getText()) for r in responses if r[1]]\n",
    "\n",
    "with open(\"rebel_text.json\", \"w\") as f:\n",
    "    json.dump(rebel_text, f)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from collections import Counter\n",
    "import json\n",
    "# get token\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"rebel_text.json\", \"r\") as f:\n",
    "    rebel_text = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebel_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to use the very popular [Spacy](https://spacy.io/) NLP package.\n",
    "\n",
    "If you are interested in learning more about Spacy, we have some notebooks [here](https://github.com/Melbourne-BMDS/md3nlp_20020) that you can run online with binder to learn more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from IPython.display import SVG, YouTubeVideo\n",
    "from spacy import displacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Entity Recognition\n",
    "\n",
    "Spacy will parse the sentences and then try to recognize different entitites that are named in the text, such as people or organizations or diseases. Let's see how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for txt in rebel_text:\n",
    "    doc = nlp(txt)\n",
    "    displacy.render(doc, style=\"ent\")\n",
    "    print('-'*72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy seems to do OK\n",
    "#### But there are some consistent failures\n",
    "\n",
    "Sometimes the solitary surnames are recognized as `ORG`s (organizations). This is not surprising because\n",
    "\n",
    "- Dyson is a vaccum cleaner\n",
    "- Tesla is a car company\n",
    "    \n",
    "The answer about Nikola Tesla is particularly problematic where we see Tesla as an organization, a piece of art, and a product---everything except a person.\n",
    "\n",
    "![Tesla labels](tesla_edison.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering Entities\n",
    "\n",
    "Let's reduce the number of the recognized entities by only keeping entities that might conceivably be one of our rebels, which in the Tesla case is a problem. Eventually my algorithm is going to count the number of times a name is mentioned to guess that the most frequently named person is the identified hero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebels = []\n",
    "labels = ['ORG', 'PERSON', 'WORK_OF_ART', 'PRODUCT']\n",
    "for txt in rebel_text:\n",
    "    doc = nlp(txt)\n",
    "    rebels.append([ent for ent in doc.ents if ent.label_ in labels and ent.string != 'Freeman' and ent.string != 'Dyson'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort identified entities\n",
    "\n",
    "I want to sort the identified entities for each document from longest to shortest. This is so that I can combine entities such as \"Albert Einstein\" and \"Einstein\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in rebels:\n",
    "    r.sort(key=lambda x:len(x.string), reverse=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With our sorted lists, we can try to replace partial names with full names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_names(r):\n",
    "    n = len(r)\n",
    "    for i in range(n-1):\n",
    "        for j in range(i,n):\n",
    "            if r[j].string in r[i].string:\n",
    "                r[j] = r[i]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use `get_full_names` to replace all partial names (e.g. 'Albert' or 'Einstein' with the full name e.g. 'Albert Einstein')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(rebels)):\n",
    "    r = rebels[i]\n",
    "    print(i)\n",
    "    print(\"Before\")\n",
    "    print(r)\n",
    "    get_full_names(r)\n",
    "    print(\"After\")\n",
    "    print(r)\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How well did it work?\n",
    "\n",
    "Most of the substitutions worked reasonably well, but cases 5 (Venter) and 6 (Tesla) clearly failed. Let's examine those to see what is happening.\n",
    "\n",
    "We are comparing the `string` attributes (`r[j].string in r[i].string`), so let's look at the strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in rebels[5]:\n",
    "    print(\"'%s'\"%ent.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in rebels[6]:\n",
    "    print(\"'%s'\"%ent.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extra Spaces!\n",
    "\n",
    "We can see that the `Venter` and `Tesla` strings have an extra space after them so our comparison 'Venter ' in 'John Craig Venter' fails. Similarly with 'Tesla '. If we use the Python `strip` method, we can delete leading and trailing white spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_names2(r):\n",
    "    n = len(r)\n",
    "    for i in range(n-1):\n",
    "        for j in range(i,n):\n",
    "            if r[j].string.strip() in r[i].string.strip():\n",
    "                r[j] = r[i]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"rebel_text.json\", \"r\") as f:\n",
    "    rebel_text = json.load(f)\n",
    "\n",
    "rebels = []\n",
    "labels = ['ORG', 'PERSON', 'WORK_OF_ART', 'PRODUCT']\n",
    "for txt in rebel_text:\n",
    "    doc = nlp(txt)\n",
    "    rebels.append([ent for ent in doc.ents if ent.label_ in labels and ent.string.strip() != 'Freeman' and ent.string.strip() != 'Dyson' and ent.string.strip() != 'Freeman Dyson'])\n",
    "\n",
    "for r in rebels:\n",
    "    r.sort(key=lambda x:len(x.string), reverse=True)\n",
    "    \n",
    "for i in range(len(rebels)):\n",
    "    r = rebels[i]\n",
    "    print(i)\n",
    "    print(\"Before\")\n",
    "    print(r)\n",
    "    get_full_names2(r)\n",
    "    print(\"After\")\n",
    "    print(r)\n",
    "    print('-'*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the identified Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counted=[Counter(r) for r in rebels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in counted:\n",
    "    print(c.most_common(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How did our counting work?\n",
    "\n",
    "Again, pretty well, but sometimes we have a name that is counted with the same frequency as a non-name entity (e.g. `(Madame Curie, 2), (a Nobel Prize, 2)`. So let's start by selecting the entities that are counted at the top-frequency and then see if we can select entities that are a `PERSON'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(counted):\n",
    "    count = counted[0][1]\n",
    "    return [c for c in counted if c[1] == count]\n",
    "\n",
    "top_counted = [most_frequent(c.most_common(5)) for c in counted if c]\n",
    "top_counted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Return the top `PERSON`\n",
    "\n",
    "If there is more than one `PERSON`, we'll just return the first one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_person(counted):\n",
    "    try:\n",
    "        return [ent for ent in counted if ent[0].label_ == 'PERSON'][0]\n",
    "    except:\n",
    "        return None\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_counted_persons = [c[0] if len(c) == 1 else get_top_person(c) for c in top_counted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_counted_persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_rebels = [e[0] for e in top_counted_persons if e]\n",
    "identified_rebels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_rebels.sort(key=lambda x:len(x.string), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_rebels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_full_names2(identified_rebels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "identified_rebels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counted_identified_rebels = Counter(identified_rebels)\n",
    "counted_identified_rebels.most_common(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1,figsize=(15,15))\n",
    "pd.DataFrame([x.string.strip() for x in identified_rebels])[0].value_counts().head(60).plot.barh(axes=axs)\n",
    "axs.set_xlabel(\"Counts\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.savefig(\"identified_rebels.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "I took a fairly simplistic approach to identifying the named rebels. The technique was not robust to several textual features, such as typos and misspellings possessive form. Because I was counting mentions of names, if someone used a lot of pronouns to refer to the rebel I might not have identified them properly. Identify the answer you submitted. Did I correctly find your rebel? If not, can you think of things in your writing that could be edited to make the identification task easier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
